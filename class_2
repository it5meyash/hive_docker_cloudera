docker start container_name
docker exec -it ac88 /bin/bash

create database db;
use db;

create table department_data                                                                                                            
    (                                                                                                                                       
    dept_id int,                                                                                                                            
    dept_name string,                                                                                                                       
    manager_id int,                                                                                                                         
    salary int)                                                                                                                             
    row format delimited                                                                                                                    
    fields terminated by ','; 
    
describe department_data;

# Shows as all file details of file where it is stored in hdfs location
describe formatted department_data;

# To see the location of file you created on hive in hdfs
hdfs dfs -ls /user/hive/file_name 

#changes in file making using vi editor
esc + wq! (to exit and save)

# For data load from local
load data local inpath 'file:///tmp/hive_class/depart_data.csv' into table department_data; 
    ---create directory and add file in tmp folder---
    ---we can copy our data from a file location to tmp folder using 
       cp "file location" "tmp location in which folder"---
       
# Display column name
set hive.cli.print.header = true;

# Load data from hdfs location
     ---first make directory using hdfs dfs -mkdir location+file_name(prefer in tmp location)---
     ---now put data from local to hdfs using hdfs fs -put /from where you're copying /where to copy---
load data inpath '/tmp/hive_data_class_2/' into table department_data_from_hdfs;

# Create external table 

create external table department_data_external                                                                                          
    > (                                                                                                                                       
    > dept_id int,                                                                                                                            
    > dept_name string,                                                                                                                       
    > manager_id int,                                                                                                                         
    > salary int                                                                                                                              
    > )                                                                                                                                       
    > row format delimited                                                                                                                    
    > fields terminated by ','                                                                                                                
    > location '/tmp/hive_data_class_2/'; 

# work with Array data types

create table employee                                                                                                                   
    > (                                                                                                                                       
    > id int,                                                                                                                                 
    > name string,                                                                                                                            
    > skills array<string>                                                                                                                    
    > )                                                                                                                                       
    > row format delimited                                                                                                                    
    > fields terminated by ','                                                                                                                
    > collection items terminated by ':';                                                                                                     

load data local inpath 'file:///tmp/hive_class/array_data.csv' into table employee; 

# Get element by index in hive array data type

select id, name, skills[0] as prime_skill from employee;

select                                                                                                                                  
    > id,                                                                                                                                     
    > name,                                                                                                                                   
    > size(skills) as size_of_each_array,                                                                                                     
    > array_contains(skills,"HADOOP") as knows_hadoop,                                                                                        
    > sort_array(skills) as sorted_array                                                                                                                     
    > from employee; 
    
    
# table for map data

create table employee_map_data                                                                                                          
    > (                                                                                                                                       
    > id int,                                                                                                                                 
    > name string,                                                                                                                            
    > details map<string,string>                                                                                                              
    > )                                                                                                                                       
    > row format delimited                                                                                                                    
    > fields terminated by ','                                                                                                                
    > collection items terminated by '|'                                                                                                      
    > map keys terminated by ':';
    
 load data local inpath 'file:///tmp/hive_class/map_data.csv' into table employee_map_data;
 
 select                                                                                                                                  
    > id,                                                                                                                                     
    > name,                                                                                                                                   
    > details["gender"] as employee_gender                                                                                                    
    > from employee_map_data; 
 
 # map functions
 select                                                                                                                                  
    > id,                                                                                                                                     
    > name,                                                                                                                                   
    > details,                                                                                                                                
    > size(details) as size_of_each_map,                                                                                                      
    > map_keys(details) as distinct_map_keys,                                                                                                 
    > map_values(details) as distinct_map_values                                                                                              
    > from employee_map_data; 



# Assignment Dataset

https://www.kaggle.com/datasets/imdevskp/corona-virus-repor

CLASS -3

# first load data as csv

create table sales_data_v2                                                                                                              
    > (                                                                                                                                       
    > p_type string,                                                                                                                          
    > total_sales int                                                                                                                         
    > )                                                                                                                                       
    > row format delimited                                                                                                                    
    > fields terminated by ','; 
    
    
load data local inpath 'file:///tmp/hive_class/sales_data_raw.csv' into table sales_data_v2; 

# command to create identical table
create table sales_data_v2_bkup as select * from sales_data_v2;

# describe command for a table
describe extended sales_data_v2;


# create a table which will store data in parquet

create table sales_data_pq_final                                                                                                        
    > (                                                                                                                                       
    > product_type string,                                                                                                                    
    > total_sales int                                                                                                                         
    > )                                                                                                                                       
    > stored as parquet;  
    
# load data in parquet file
from sales_data_v2 insert overwrite table sales_data_pq_final select *;

CLASS -4


















